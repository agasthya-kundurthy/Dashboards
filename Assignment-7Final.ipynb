{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue from the Assignment 2 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file1 = pandas.read_csv('Assignment-2-CleanedData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Unwanted column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file1.drop('Unnamed: 0', axis=1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import pandas_datareader as pdr\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data from JSON for ticker symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import urllib\n",
    "\n",
    "def get_TickerSymbol(companyName):\n",
    "    url = \"http://d.yimg.com/autoc.finance.yahoo.com/autoc?query={}&region=1&lang=en\".format(companyName)\n",
    "\n",
    "    result = requests.get(url).json()\n",
    "    \n",
    "    for x in result['ResultSet']['Result']:\n",
    "                    return x['symbol']\n",
    "        \n",
    "\n",
    "arrTicker=[]\n",
    "comp_name = file1.Entity\n",
    "\n",
    "    \n",
    "for  name in comp_name:\n",
    "    arrTicker.append(get_TickerSymbol(name))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect share data between two dates for companies with ticker symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/agasthya/anaconda3/lib/python3.6/site-packages/pandas_datareader/yahoo/daily.py:136: SymbolWarning: Failed to read symbol: 'AOL', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "/Users/agasthya/anaconda3/lib/python3.6/site-packages/pandas_datareader/yahoo/daily.py:136: SymbolWarning: Failed to read symbol: None, replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "/Users/agasthya/anaconda3/lib/python3.6/site-packages/pandas_datareader/yahoo/daily.py:136: SymbolWarning: Failed to read symbol: 'CIT-U.TI', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "/Users/agasthya/anaconda3/lib/python3.6/site-packages/pandas_datareader/yahoo/daily.py:136: SymbolWarning: Failed to read symbol: '^UMIAMIFL', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "/Users/agasthya/anaconda3/lib/python3.6/site-packages/pandas_datareader/yahoo/daily.py:136: SymbolWarning: Failed to read symbol: 'JPM-PB', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "/Users/agasthya/anaconda3/lib/python3.6/site-packages/pandas_datareader/yahoo/daily.py:136: SymbolWarning: Failed to read symbol: 'KCT.V', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "/Users/agasthya/anaconda3/lib/python3.6/site-packages/pandas_datareader/yahoo/daily.py:136: SymbolWarning: Failed to read symbol: 'LNKD', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "/Users/agasthya/anaconda3/lib/python3.6/site-packages/pandas_datareader/yahoo/daily.py:136: SymbolWarning: Failed to read symbol: 'NMBS.KL', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "/Users/agasthya/anaconda3/lib/python3.6/site-packages/pandas_datareader/yahoo/daily.py:136: SymbolWarning: Failed to read symbol: 'CPWFF8.EX', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n",
      "/Users/agasthya/anaconda3/lib/python3.6/site-packages/pandas_datareader/yahoo/daily.py:136: SymbolWarning: Failed to read symbol: 'FLINGX', replacing with NaN.\n",
      "  warnings.warn(msg.format(sym), SymbolWarning)\n"
     ]
    }
   ],
   "source": [
    "start = dt.datetime(2004,1,1)\n",
    "end = dt.datetime(2017,6,6)\n",
    "panel_data = pdr.DataReader(arrTicker, 'yahoo', start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pandas.core.panel.Panel'>\n",
       "Dimensions: 6 (items) x 3799 (major_axis) x 61 (minor_axis)\n",
       "Items axis: Adj Close to Volume\n",
       "Major_axis axis: 2004-01-01 00:00:00 to 2017-06-07 00:00:00\n",
       "Minor_axis axis: ADP to FLINGX"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The index in this DataFrame is the major index of the panel_data.\n",
    "finalData = panel_data.ix['Close']\n",
    "\n",
    "# Getting all weekdays between 01/01/2000 and 12/31/2016\n",
    "all_weekdays = pandas.date_range(start=start, end=end, freq='B')\n",
    "\n",
    "# How do we align the existing prices in adj_close with our new set of dates?\n",
    "# All we need to do is reindex close using all_weekdays as the new index\n",
    "finalData = finalData.reindex(all_weekdays)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalData2 = finalData.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalData2 = finalData.groupby(pandas.TimeGrouper(freq='12M')).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalData2 = finalData2.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "newDataFrame= pandas.DataFrame(columns=['Symbol','Date','Price'])\n",
    "k =0\n",
    "for i in range(len(finalData2)) : \n",
    "    ts = finalData2.index[i]\n",
    "    for j in range(len(finalData2.iloc[i])): \n",
    "        time_frame = pandas.to_datetime(str(finalData2.columns.values[j]))\n",
    "        date = time_frame.strftime('%Y-%m-%d')\n",
    "        newDataFrame.loc[k]=( ts,  date , finalData2.iloc[i][j])\n",
    "        k=k+1\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADP</td>\n",
       "      <td>2004-01-31</td>\n",
       "      <td>32.813820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADP</td>\n",
       "      <td>2005-01-31</td>\n",
       "      <td>34.064935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADP</td>\n",
       "      <td>2006-01-31</td>\n",
       "      <td>35.050695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADP</td>\n",
       "      <td>2007-01-31</td>\n",
       "      <td>36.863325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADP</td>\n",
       "      <td>2008-01-31</td>\n",
       "      <td>40.408635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol        Date      Price\n",
       "0    ADP  2004-01-31  32.813820\n",
       "1    ADP  2005-01-31  34.064935\n",
       "2    ADP  2006-01-31  35.050695\n",
       "3    ADP  2007-01-31  36.863325\n",
       "4    ADP  2008-01-31  40.408635"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newDataFrame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the year format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newDataFrame.loc[newDataFrame['Date'] == '2005-01-31', 'Date'] = '2004'\n",
    "newDataFrame.loc[newDataFrame['Date'] == '2006-01-31', 'Date'] = '2005'\n",
    "newDataFrame.loc[newDataFrame['Date'] == '2007-01-31', 'Date'] = '2006'\n",
    "newDataFrame.loc[newDataFrame['Date'] == '2008-01-31', 'Date'] = '2007'\n",
    "newDataFrame.loc[newDataFrame['Date'] == '2009-01-31', 'Date'] = '2008'\n",
    "newDataFrame.loc[newDataFrame['Date'] == '2010-01-31', 'Date'] = '2009'\n",
    "newDataFrame.loc[newDataFrame['Date'] == '2011-01-31', 'Date'] = '2010'\n",
    "newDataFrame.loc[newDataFrame['Date'] == '2012-01-31', 'Date'] = '2011'\n",
    "newDataFrame.loc[newDataFrame['Date'] == '2013-01-31', 'Date'] = '2012'\n",
    "newDataFrame.loc[newDataFrame['Date'] == '2014-01-31', 'Date'] = '2013'\n",
    "newDataFrame.loc[newDataFrame['Date'] == '2015-01-31', 'Date'] = '2014'\n",
    "newDataFrame.loc[newDataFrame['Date'] == '2016-01-31', 'Date'] = '2015'\n",
    "newDataFrame.loc[newDataFrame['Date'] == '2017-01-31', 'Date'] = '2016'\n",
    "newDataFrame.loc[newDataFrame['Date'] == '2018-01-31', 'Date'] = '2017'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Change the Date to year before. ignoring 2004. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newDataFrame = newDataFrame[newDataFrame['Date'] != '2004-01-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save Data to a file\n",
    "newDataFrame.to_csv('Assignment3_FinanceFinalData.csv', index=True, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_ticker = pandas.DataFrame(arrTicker) \n",
    "data_ticker['Ticker_Symbol'] = pandas.Series(arrTicker, index=data_ticker.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file1['Ticker_symbol']= data_ticker['Ticker_Symbol']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file1 = file1.dropna(axis=0,how='any')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Year</th>\n",
       "      <th>Records Lost</th>\n",
       "      <th>Organisation</th>\n",
       "      <th>Method of Leak</th>\n",
       "      <th>Data Sensitivity</th>\n",
       "      <th>Ticker_symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AOL</td>\n",
       "      <td>2004</td>\n",
       "      <td>92000000</td>\n",
       "      <td>web</td>\n",
       "      <td>inside job</td>\n",
       "      <td>E-mail Address or Online Information</td>\n",
       "      <td>AOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Automatic Data Processing</td>\n",
       "      <td>2005</td>\n",
       "      <td>125000</td>\n",
       "      <td>financial</td>\n",
       "      <td>poor security</td>\n",
       "      <td>SSN/Personal Details</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Citigroup</td>\n",
       "      <td>2005</td>\n",
       "      <td>3900000</td>\n",
       "      <td>financial</td>\n",
       "      <td>lost / stolen device</td>\n",
       "      <td>Credit Card Information</td>\n",
       "      <td>CIT-U.TI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hewlett Packard</td>\n",
       "      <td>2006</td>\n",
       "      <td>200000</td>\n",
       "      <td>tech, retail</td>\n",
       "      <td>lost / stolen device</td>\n",
       "      <td>SSN/Personal Details</td>\n",
       "      <td>HPQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KDDI</td>\n",
       "      <td>2006</td>\n",
       "      <td>4000000</td>\n",
       "      <td>telecoms</td>\n",
       "      <td>hacked</td>\n",
       "      <td>E-mail Address or Online Information</td>\n",
       "      <td>KDDIF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Entity  Year  Records Lost  Organisation  \\\n",
       "0                        AOL  2004      92000000           web   \n",
       "1  Automatic Data Processing  2005        125000     financial   \n",
       "3                  Citigroup  2005       3900000     financial   \n",
       "5            Hewlett Packard  2006        200000  tech, retail   \n",
       "7                       KDDI  2006       4000000      telecoms   \n",
       "\n",
       "         Method of Leak                      Data Sensitivity Ticker_symbol  \n",
       "0            inside job  E-mail Address or Online Information           AOL  \n",
       "1         poor security                  SSN/Personal Details           ADP  \n",
       "3  lost / stolen device               Credit Card Information      CIT-U.TI  \n",
       "5  lost / stolen device                  SSN/Personal Details           HPQ  \n",
       "7                hacked  E-mail Address or Online Information         KDDIF  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file1.to_csv('Assignment7_FinanceData.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original Claim -\n",
    "'Data breaches are not punished by stock market' as long as the company is well received or followed by customers. Facebook is the classic example, even when there was a data breach, the stock price of Facebook never really came down and was always increasing because of its popularity and ever increasing user base.\n",
    "The dashboard shows the graph of stock price of Facebook.\n",
    "\n",
    "Purpose of Redesign - \n",
    "The purpose of this redesign is to take a look at the old visualization and understand if there needs to be a change in the way the previous version has been represented. \n",
    "\n",
    "Original vs Redesign\n",
    "\n",
    "The claim from my previous visualization is that ‘Data breaches are not punished by stock markets. The redesign of the earlier visualization also supports the same claim, the visualization is also similar to the previous one and has very little changes. I feel that this visualization has just about enough data that supports my claim but I have now excluded the part of the graph which gives information about all the data breaches, the type of breach and number of records lost during those breaches. I feel this information in a final presentation of the data in unnecessary because it doesn’t provide any required additional data to support my claim for the visualization and also it might not be the best way to present my data to the users and make them read more. The graph which shows that Facebook’s stock price was not affected by the data breach, the stock price kept on increasing, this graph is sufficient to support my claim. I have also converted this graph to a simple line chart. The final graph gives an idea of how Facebook's share price were not affected by the data breach that had occured. The share price kept increasing steadily due to the companies customer base and popularity.\n",
    "\n",
    "\n",
    "If I had more data on the exact dates of the breaches, the dates that the companies announced about these breaches, that would be a better case as it would be possible to look at multiple companies who might have lost their stock price due to these breaches and not because of other market fluctuations such as Citi bank which lost its share price due the market meltdown in 2008-09.\n",
    "\n",
    "Link to Tableau Public for Original - \n",
    "https://public.tableau.com/profile/aashreya.agasthya.kundurthy#!/vizhome/assignment3_1_1/Dashboard1?publish=yes\n",
    "\n",
    "Link to Tableau Public for Redesign -\n",
    "https://public.tableau.com/profile/aashreya.agasthya.kundurthy#!/vizhome/Assignment-7_0/Redesigned-Dashboard?publish=yes\n",
    "\n",
    "Reference -\n",
    "https://docs.google.com/spreadsheets/d/1Je-YUdnhjQJO_13r8iTeRxpU2pBKuV6RVRHoYCgiMfg/edit#gid=322165570\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
